#!/usr/bin/env python3
"""
SEO Cross-Testing Runner
========================

–û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∫—Ä–æ—Å—Å-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è SEO –∞–≥–µ–Ω—Ç–∞.
–í–∫–ª—é—á–∞–µ—Ç –≤—Å–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: Lighthouse, PageSpeed, Schema.org, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ SEO.
"""

import asyncio
import json
import os
import sys
import argparse
from datetime import datetime
from pathlib import Path
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from seo_cross_testing import SEOCrossTestingSystem
from seo_performance_validator import SEOPerformanceValidator

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class SEOTestingOrchestrator:
    """–û—Ä–∫–µ—Å—Ç—Ä–∞—Ç–æ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤—Å–µ–º–∏ SEO —Ç–µ—Å—Ç–∞–º–∏"""
    
    def __init__(self, pagespeed_api_key=None):
        self.cross_testing_system = SEOCrossTestingSystem()
        self.performance_validator = SEOPerformanceValidator(pagespeed_api_key)
        self.results_dir = Path("seo_test_results")
        self.results_dir.mkdir(exist_ok=True)
    
    async def run_complete_validation(self, urls: list, output_format='json'):
        """–ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è —Å–ø–∏—Å–∫–∞ URL"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —ç—Ç–æ–≥–æ –∑–∞–ø—É—Å–∫–∞
        session_dir = self.results_dir / f"session_{timestamp}"
        session_dir.mkdir(exist_ok=True)
        
        logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {len(urls)} URL")
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {session_dir}")
        
        all_results = {
            'session_info': {
                'timestamp': timestamp,
                'urls_count': len(urls),
                'test_types': ['lighthouse', 'pagespeed_mobile', 'pagespeed_desktop', 'schema_validation', 'technical_seo', 'content_quality']
            },
            'results': {},
            'summary': {},
            'comparison': {}
        }
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π URL
        for i, url in enumerate(urls, 1):
            logger.info(f"[{i}/{len(urls)}] –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ: {url}")
            
            try:
                # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±–∞ —Ç–∏–ø–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
                cross_test_task = self.cross_testing_system.run_comprehensive_test(url)
                performance_test_task = self.performance_validator.comprehensive_validation(url)
                
                cross_results, performance_results = await asyncio.gather(
                    cross_test_task, performance_test_task, return_exceptions=True
                )
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                url_results = {
                    'url': url,
                    'timestamp': datetime.now().isoformat(),
                    'cross_testing': cross_results if not isinstance(cross_results, Exception) else {'error': str(cross_results)},
                    'performance_validation': performance_results if not isinstance(performance_results, Exception) else {'error': str(performance_results)}
                }
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
                url_results['combined_analysis'] = self._combine_results(cross_results, performance_results)
                
                all_results['results'][url] = url_results
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                url_filename = url.replace('/', '_').replace(':', '_').replace('?', '_')
                individual_file = session_dir / f"{url_filename}.json"
                
                with open(individual_file, 'w', encoding='utf-8') as f:
                    json.dump(url_results, f, indent=2, ensure_ascii=False, default=str)
                
                logger.info(f"‚úì –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {url} –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
                
            except Exception as e:
                logger.error(f"‚úó –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ {url}: {str(e)}")
                all_results['results'][url] = {
                    'url': url,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                }
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–≤–æ–¥–∫—É –∏ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        all_results['summary'] = self._generate_summary(all_results['results'])
        all_results['comparison'] = self._generate_comparison(all_results['results'])
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç
        full_report_file = session_dir / "full_report.json"
        with open(full_report_file, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, indent=2, ensure_ascii=False, default=str)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º HTML –æ—Ç—á–µ—Ç
        if output_format in ['html', 'both']:
            html_report = self._generate_html_report(all_results)
            html_file = session_dir / "report.html"
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_report)
        
        logger.info(f"üéâ –ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        logger.info(f"üìä –ü–æ–ª–Ω—ã–π –æ—Ç—á–µ—Ç: {full_report_file}")
        
        return all_results
    
    def _combine_results(self, cross_results, performance_results):
        """–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤"""
        
        if isinstance(cross_results, Exception) or isinstance(performance_results, Exception):
            return {'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫ –≤ —Ç–µ—Å—Ç–∞—Ö'}
        
        combined = {
            'overall_health_score': 0,
            'critical_issues': [],
            'improvement_priorities': [],
            'seo_readiness': 'unknown'
        }
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ—Ü–µ–Ω–∫–∏
        scores = []
        
        # –ò–∑ –∫—Ä–æ—Å—Å-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        for test_type, result in cross_results.items():
            if hasattr(result, 'score'):
                scores.append(result.score)
        
        # –ò–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        if 'overall_score' in performance_results:
            scores.append(performance_results['overall_score'])
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É –∑–¥–æ—Ä–æ–≤—å—è
        if scores:
            combined['overall_health_score'] = round(sum(scores) / len(scores), 2)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã
        critical_issues = set()
        
        # –ò–∑ –∫—Ä–æ—Å—Å-—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        for test_type, result in cross_results.items():
            if hasattr(result, 'issues'):
                for issue in result.issues:
                    if any(keyword in issue.lower() for keyword in ['–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç title', '–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç h1', '–æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç meta description']):
                        critical_issues.add(issue)
        
        # –ò–∑ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        perf_recommendations = performance_results.get('recommendations', [])
        for rec in perf_recommendations:
            if rec.get('priority') == 'high':
                critical_issues.add(rec['text'])
        
        combined['critical_issues'] = list(critical_issues)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã —É–ª—É—á—à–µ–Ω–∏–π
        priorities = []
        
        if combined['overall_health_score'] < 60:
            priorities.append('–ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ SEO –æ—Å–Ω–æ–≤')
        elif combined['overall_health_score'] < 80:
            priorities.append('–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ SEO')
        else:
            priorities.append('–¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –∏ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–±–∏–ª—å–Ω—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        mobile_perf = performance_results.get('mobile_performance', {})
        if mobile_perf.get('performance_score', 100) < 70:
            priorities.append('–£–ª—É—á—à–µ–Ω–∏–µ –º–æ–±–∏–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏')
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        schema_validation = performance_results.get('schema_validation', {})
        if not schema_validation.get('valid_schemas'):
            priorities.append('–î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö')
        
        combined['improvement_priorities'] = priorities
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å –∫ SEO
        if combined['overall_health_score'] >= 90:
            combined['seo_readiness'] = 'excellent'
        elif combined['overall_health_score'] >= 80:
            combined['seo_readiness'] = 'good'
        elif combined['overall_health_score'] >= 60:
            combined['seo_readiness'] = 'fair'
        else:
            combined['seo_readiness'] = 'poor'
        
        return combined
    
    def _generate_summary(self, results):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        
        summary = {
            'total_urls': len(results),
            'successful_tests': 0,
            'failed_tests': 0,
            'average_scores': {},
            'common_issues': [],
            'best_performing_url': None,
            'worst_performing_url': None
        }
        
        all_scores = []
        all_issues = []
        url_scores = {}
        
        for url, result in results.items():
            if 'error' in result:
                summary['failed_tests'] += 1
                continue
            
            summary['successful_tests'] += 1
            
            # –°–æ–±–∏—Ä–∞–µ–º –æ—Ü–µ–Ω–∫–∏
            combined = result.get('combined_analysis', {})
            score = combined.get('overall_health_score', 0)
            
            if score > 0:
                all_scores.append(score)
                url_scores[url] = score
            
            # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–ª–µ–º—ã
            critical_issues = combined.get('critical_issues', [])
            all_issues.extend(critical_issues)
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏
        if all_scores:
            summary['average_scores']['overall'] = round(sum(all_scores) / len(all_scores), 2)
        
        # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º—ã–µ —á–∞—Å—Ç—ã–µ –ø—Ä–æ–±–ª–µ–º—ã
        from collections import Counter
        issue_counts = Counter(all_issues)
        summary['common_issues'] = [
            {'issue': issue, 'count': count}
            for issue, count in issue_counts.most_common(5)
        ]
        
        # –ù–∞—Ö–æ–¥–∏–º –ª—É—á—à–∏–π –∏ —Ö—É–¥—à–∏–π URL
        if url_scores:
            best_url = max(url_scores, key=url_scores.get)
            worst_url = min(url_scores, key=url_scores.get)
            
            summary['best_performing_url'] = {
                'url': best_url,
                'score': url_scores[best_url]
            }
            
            summary['worst_performing_url'] = {
                'url': worst_url,
                'score': url_scores[worst_url]
            }
        
        return summary
    
    def _generate_comparison(self, results):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        
        comparison = {
            'score_distribution': {
                'excellent': 0,  # 90-100
                'good': 0,       # 80-89
                'fair': 0,       # 60-79
                'poor': 0        # 0-59
            },
            'test_consistency': {},
            'improvement_recommendations': []
        }
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –æ—Ü–µ–Ω–æ–∫
        for url, result in results.items():
            if 'error' in result:
                continue
            
            combined = result.get('combined_analysis', {})
            score = combined.get('overall_health_score', 0)
            
            if score >= 90:
                comparison['score_distribution']['excellent'] += 1
            elif score >= 80:
                comparison['score_distribution']['good'] += 1
            elif score >= 60:
                comparison['score_distribution']['fair'] += 1
            else:
                comparison['score_distribution']['poor'] += 1
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–≥–ª–∞—Å–æ–≤–∞–Ω–Ω–æ—Å—Ç—å —Ç–µ—Å—Ç–æ–≤
        lighthouse_scores = []
        pagespeed_scores = []
        
        for url, result in results.items():
            if 'error' in result:
                continue
            
            cross_results = result.get('cross_testing', {})
            perf_results = result.get('performance_validation', {})
            
            # Lighthouse –æ—Ü–µ–Ω–∫–∏
            lighthouse_result = cross_results.get('lighthouse')
            if lighthouse_result and hasattr(lighthouse_result, 'score'):
                lighthouse_scores.append(lighthouse_result.score)
            
            # PageSpeed –æ—Ü–µ–Ω–∫–∏
            overall_score = perf_results.get('overall_score', 0)
            if overall_score > 0:
                pagespeed_scores.append(overall_score)
        
        if lighthouse_scores and pagespeed_scores:
            import statistics
            
            comparison['test_consistency'] = {
                'lighthouse_avg': round(statistics.mean(lighthouse_scores), 2),
                'pagespeed_avg': round(statistics.mean(pagespeed_scores), 2),
                'score_variance': round(abs(statistics.mean(lighthouse_scores) - statistics.mean(pagespeed_scores)), 2)
            }
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
        poor_count = comparison['score_distribution']['poor']
        fair_count = comparison['score_distribution']['fair']
        
        if poor_count > 0:
            comparison['improvement_recommendations'].append(
                f"üî¥ –ö—Ä–∏—Ç–∏—á–Ω–æ: {poor_count} —Å—Ç—Ä–∞–Ω–∏—Ü —Ç—Ä–µ–±—É—é—Ç –Ω–µ–º–µ–¥–ª–µ–Ω–Ω–æ–≥–æ —É–ª—É—á—à–µ–Ω–∏—è SEO"
            )
        
        if fair_count > 0:
            comparison['improvement_recommendations'].append(
                f"üü° –í–Ω–∏–º–∞–Ω–∏–µ: {fair_count} —Å—Ç—Ä–∞–Ω–∏—Ü –Ω—É–∂–¥–∞—é—Ç—Å—è –≤ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"
            )
        
        if comparison['test_consistency'].get('score_variance', 0) > 20:
            comparison['improvement_recommendations'].append(
                "‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–∞—Å—Ö–æ–∂–¥–µ–Ω–∏—è –º–µ–∂–¥—É —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ SEO –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞–º–∏"
            )
        
        return comparison
    
    def _generate_html_report(self, results):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è HTML –æ—Ç—á–µ—Ç–∞"""
        
        html_template = """
<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>SEO Cross-Testing Report</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            line-height: 1.6;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        .header {
            text-align: center;
            border-bottom: 2px solid #eee;
            padding-bottom: 20px;
            margin-bottom: 30px;
        }
        .summary-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }
        .metric-card {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #007bff;
        }
        .metric-value {
            font-size: 2em;
            font-weight: bold;
            color: #007bff;
        }
        .metric-label {
            color: #666;
            margin-top: 5px;
        }
        .url-results {
            margin-top: 30px;
        }
        .url-card {
            background: white;
            border: 1px solid #ddd;
            border-radius: 8px;
            margin-bottom: 20px;
            overflow: hidden;
        }
        .url-header {
            background: #f8f9fa;
            padding: 15px 20px;
            border-bottom: 1px solid #ddd;
        }
        .url-content {
            padding: 20px;
        }
        .score-badge {
            display: inline-block;
            padding: 4px 12px;
            border-radius: 20px;
            color: white;
            font-weight: bold;
            margin-right: 10px;
        }
        .score-excellent { background: #28a745; }
        .score-good { background: #ffc107; color: #212529; }
        .score-fair { background: #fd7e14; }
        .score-poor { background: #dc3545; }
        .issues-list {
            list-style: none;
            padding: 0;
        }
        .issues-list li {
            padding: 5px 0;
            border-bottom: 1px solid #eee;
        }
        .priority-high { color: #dc3545; font-weight: bold; }
        .priority-medium { color: #fd7e14; font-weight: bold; }
        .priority-low { color: #28a745; }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üîç SEO Cross-Testing Report</h1>
            <p>–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ SEO –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏</p>
            <p><strong>–î–∞—Ç–∞ —Å–æ–∑–¥–∞–Ω–∏—è:</strong> {timestamp}</p>
        </div>
        
        <div class="summary-grid">
            <div class="metric-card">
                <div class="metric-value">{total_urls}</div>
                <div class="metric-label">–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–æ URL</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{successful_tests}</div>
                <div class="metric-label">–£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{average_score:.1f}</div>
                <div class="metric-label">–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞</div>
            </div>
            <div class="metric-card">
                <div class="metric-value">{excellent_count}</div>
                <div class="metric-label">–û—Ç–ª–∏—á–Ω—ã—Ö —Å—Ç—Ä–∞–Ω–∏—Ü</div>
            </div>
        </div>
        
        <h2>üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ URL</h2>
        <div class="url-results">
            {url_results_html}
        </div>
        
        <h2>üéØ –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏</h2>
        <ul>
            {recommendations_html}
        </ul>
    </div>
</body>
</html>
        """
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —à–∞–±–ª–æ–Ω–∞
        summary = results.get('summary', {})
        comparison = results.get('comparison', {})
        
        # URL —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        url_results_html = ""
        for url, result in results.get('results', {}).items():
            if 'error' in result:
                continue
            
            combined = result.get('combined_analysis', {})
            score = combined.get('overall_health_score', 0)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏
            if score >= 90:
                score_class = 'score-excellent'
            elif score >= 80:
                score_class = 'score-good'
            elif score >= 60:
                score_class = 'score-fair'
            else:
                score_class = 'score-poor'
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–æ–∫ –ø—Ä–æ–±–ª–µ–º
            issues_html = ""
            for issue in combined.get('critical_issues', [])[:5]:
                issues_html += f"<li>‚ùå {issue}</li>"
            
            url_results_html += f"""
            <div class="url-card">
                <div class="url-header">
                    <h3>{url}</h3>
                    <span class="score-badge {score_class}">{score:.1f}/100</span>
                </div>
                <div class="url-content">
                    <h4>–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã:</h4>
                    <ul class="issues-list">
                        {issues_html}
                    </ul>
                </div>
            </div>
            """
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        recommendations_html = ""
        for rec in comparison.get('improvement_recommendations', []):
            recommendations_html += f"<li>{rec}</li>"
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º —à–∞–±–ª–æ–Ω
        html_content = html_template.format(
            timestamp=datetime.now().strftime("%d.%m.%Y %H:%M:%S"),
            total_urls=summary.get('total_urls', 0),
            successful_tests=summary.get('successful_tests', 0),
            average_score=summary.get('average_scores', {}).get('overall', 0),
            excellent_count=comparison.get('score_distribution', {}).get('excellent', 0),
            url_results_html=url_results_html,
            recommendations_html=recommendations_html
        )
        
        return html_content

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    parser = argparse.ArgumentParser(description='SEO Cross-Testing System')
    parser.add_argument('--urls', nargs='+', help='URLs –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è')
    parser.add_argument('--urls-file', help='–§–∞–π–ª —Å URLs (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É)')
    parser.add_argument('--output-format', choices=['json', 'html', 'both'], default='both', help='–§–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞')
    parser.add_argument('--pagespeed-api-key', help='API –∫–ª—é—á –¥–ª—è PageSpeed Insights')
    
    args = parser.parse_args()
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º URLs –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    test_urls = []
    
    if args.urls:
        test_urls.extend(args.urls)
    
    if args.urls_file:
        try:
            with open(args.urls_file, 'r') as f:
                file_urls = [line.strip() for line in f if line.strip()]
                test_urls.extend(file_urls)
        except FileNotFoundError:
            logger.error(f"–§–∞–π–ª {args.urls_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return
    
    # –ï—Å–ª–∏ URLs –Ω–µ —É–∫–∞–∑–∞–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ
    if not test_urls:
        test_urls = [
            "http://localhost:8000/good_seo_test.html",
            "http://localhost:8000/bad_seo_test.html", 
            "http://localhost:8000/ecommerce_test.html"
        ]
        logger.info("–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Ç–µ—Å—Ç–æ–≤—ã–µ URLs")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    orchestrator = SEOTestingOrchestrator(args.pagespeed_api_key)
    
    try:
        results = await orchestrator.run_complete_validation(test_urls, args.output_format)
        
        # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
        summary = results.get('summary', {})
        print(f"\n{'='*60}")
        print("üéâ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
        print(f"{'='*60}")
        print(f"üìä –í—Å–µ–≥–æ URL: {summary.get('total_urls', 0)}")
        print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {summary.get('successful_tests', 0)}")
        print(f"‚ùå –ù–µ—É–¥–∞—á–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {summary.get('failed_tests', 0)}")
        print(f"üìà –°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞: {summary.get('average_scores', {}).get('overall', 0):.1f}/100")
        
        best_url = summary.get('best_performing_url')
        if best_url:
            print(f"üèÜ –õ—É—á—à–∏–π URL: {best_url['url']} ({best_url['score']:.1f}/100)")
        
        worst_url = summary.get('worst_performing_url')
        if worst_url:
            print(f"üî¥ –¢—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è: {worst_url['url']} ({worst_url['score']:.1f}/100)")
        
        print(f"\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {orchestrator.results_dir}/session_*")
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {str(e)}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(asyncio.run(main()))
